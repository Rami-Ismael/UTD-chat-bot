{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is we create a persona\n",
    "Creating a prompt with a persona is a method of generating questions that are targeted towards a specific user group, \n",
    "in this case prospective students and applicants of the University of Texas at Dallas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports libraries and setup\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # take environment variables from .env.\n",
    "#setting up OpenAI Api\n",
    "OPENKEY_API = os.getenv(\"OPENAI_KEY\")\n",
    "ORGANIZATION_ID = os.getenv(\"ORGANIZATION_ID\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENKEY_API\n",
    "openai.organization = ORGANIZATION_ID\n",
    "# get this from top-right dropdown on OpenAI under organization > settings\n",
    "openai.api_key = OPENKEY_API"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fields"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Majors\n",
    "1. Computer Science\n",
    "2. Computer Engineering\n",
    "3. Electrical Engineering\n",
    "4. Mechanical Engineering\n",
    "5. Mathematics\n",
    "6. ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAJORS = [\n",
    "    \"Arts and Technology\",\n",
    "    \"Emerging Media and Communication\",\n",
    "    \"Accounting\",\n",
    "    \"Business Administration\",\n",
    "    \"Business Analytics\",\n",
    "    \"Energy Management\",\n",
    "    \"Finance\",\n",
    "    \"Healthcare Management\",\n",
    "    \"Information Technology and Systems\",\n",
    "    \"Innovation and Entrepreneurship\",\n",
    "    \"International Management Studies\",\n",
    "    \"Management\",\n",
    "    \"Marketing\",\n",
    "    \"Supply Chain Management\",\n",
    "    \"Aerospace Engineering\",\n",
    "    \"Bioengineering\",\n",
    "    \"Computer Engineering\",\n",
    "    \"Computer Science\",\n",
    "    \"Cybersecurity\",\n",
    "    \"Electrical Engineering\",\n",
    "    \"Materials Science and Engineering\",\n",
    "    \"Mechanical Engineering\",\n",
    "    \"Software Engineering\",\n",
    "    \"Applied Behavior Analysis\",\n",
    "    \"Audiology\",\n",
    "    \"Child Learning and Development\",\n",
    "    \"Cognition and Neuroscience\",\n",
    "    \"Communication Disorders\",\n",
    "    \"Criminology\",\n",
    "    \"Developmental Psychology\",\n",
    "    \"Neuroscience\",\n",
    "    \"Economics\",\n",
    "    \"Geospatial Information Sciences\",\n",
    "    \"International Political Economy\",\n",
    "    \"International Relations\",\n",
    "    \"Political Science\",\n",
    "    \"Public Affairs\",\n",
    "    \"Public Policy and Political Economy\",\n",
    "    \"Sociology\",\n",
    "    \"Actuarial Science\",\n",
    "    \"Applied Mathematics\",\n",
    "    \"Biology\",\n",
    "    \"Chemistry\",\n",
    "    \"Data Science\",\n",
    "    \"Geosciences\",\n",
    "    \"Mathematics\",\n",
    "    \"Molecular and Cell Biology\",\n",
    "    \"Physics\",\n",
    "    \"Statistics\"\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Pesona Prompt using ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print\n",
    "prompt = \"Provide a list of questions that a student at University of Texas at Dallas  would create in number format\"\n",
    "\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\", \n",
    "  messages = [\n",
    "        {\"role\": \"system\", \"content\" : \"You are ChatGPT, a large language model trained by OpenAI. Follow the user's instructions carefully. Respond using markdown.\\nKnowledge cutoff: 2021-09-01\\nCurrent date: 2023-03-02\"},\n",
    "        {\"role\": \"user\", \"content\" : prompt},\n",
    "  ]\n",
    ")\n",
    "print( response )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess (chatgpt_response) -> str:\n",
    "    #print( chatgpt_response)\n",
    "    ## Split the response into a list of instructions\n",
    "    list_instruction = chatgpt_response['choices'][0]['message'][\"content\"].split('\\n')\n",
    "    list_instruction = [instruction for instruction in list_instruction if instruction != '']\n",
    "    print(list_instruction)\n",
    "    ## remoe all the instruction that does not have a number and dot afterward\n",
    "    list_instruction = [instruction for instruction in list_instruction if instruction[0].isdigit() and instruction[1] == '.']\n",
    "    ## Remove the number listed in the list of instructions\n",
    "    list_instruction = [instruction.split('.',1)[1] for instruction in list_instruction]\n",
    "    print(list_instruction)\n",
    "    ## Remove trailing spaces\n",
    "    list_instruction = [instruction.strip() for instruction in list_instruction]\n",
    "    #print(list_instruction)\n",
    "    return list_instruction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store the instruction in a Pandas Dataframe that will be saved using in a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_the_persona_question(chatgpt_response , **kwargs):\n",
    "    import pandas as pd\n",
    "    list_of_instructions = preprocess(chatgpt_response)\n",
    "    # Store the list of instructions in a new csv file instruction_dataet.csv\n",
    "    answer = pd.DataFrame( list_of_instructions, columns=['Question'])\n",
    "    ## add new column date_created\n",
    "    answer['date_created'] = pd.to_datetime('today')\n",
    "    ## what model was used to generate the instructions\n",
    "    answer['model'] = 'gpt-3.5-turbo'\n",
    "    for key, value in kwargs.items():\n",
    "        answer[key] = value\n",
    "    ## The prompt of the model\n",
    "    #print(f\"The columns of the dataframe are {answer.columns}\")\n",
    "    #answer['prompt'] = PROMPT\n",
    "    #print(f\"The columns of the dataframe are {answer.columns}\")\n",
    "    #print(answer)\n",
    "    ## save the dataframe to a csv file\n",
    "    # Load to the instruction dataset.csv\n",
    "    load_csv = pd.read_csv('evaluation.csv')\n",
    "    load_dataset = pd.concat([load_csv, answer], ignore_index=True)\n",
    "    #answer.to_csv('instruction_dataset.csv', index=False)\n",
    "    load_dataset.to_csv('evaluation.csv', index=False)\n",
    "    #answer.to_csv('instruction_dataset.csv', index=False)\n",
    "    #answer.to_csv('evaluation.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Format with different foramt \n",
    "1. What type of majors\n",
    "Initial Prompt\n",
    "```\n",
    "prompt = \"Provide a list of questions that a student {{who is {majoring}}} at University of Texas at Dallas  would create in number format\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print\n",
    "\n",
    "\n",
    "#print( completion )\n",
    "for major in MAJORS:\n",
    "  prompt = f\"Provide a list of questions that a student who is {major} at University of Texas at Dallas  would create in number format\"\n",
    "  completion = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\", \n",
    "  messages = [\n",
    "        {\"role\": \"system\", \"content\" : \"You are ChatGPT, a large language model trained by OpenAI. Follow the user's instructions carefully. Respond using markdown.\\nKnowledge cutoff: 2021-09-01\\nCurrent date: 2023-03-02\"},\n",
    "        {\"role\": \"user\", \"content\" : prompt},\n",
    "  ],\n",
    "  temperature = 1,\n",
    "  top_p = 1,\n",
    "  )\n",
    "  store_the_persona_question(completion, major=major , prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_instructions = preprocess(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add the context of the grades of the person is the preson a freshman, sophmore, junior, senior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print\n",
    "\n",
    "\n",
    "print( completion )\n",
    "for grade in [\"undergraduate freshman\", \" undergraduate sophomore\", \"undergraduate junior\", \"undergraduate senior\" , \"master\", \"PHD\"]:\n",
    "    for major in MAJORS:\n",
    "        prompt = f\"Provide a list of questions that a {grade} {major} student at UTD  would in number format.t\"\n",
    "        completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\", \n",
    "        messages = [\n",
    "                {\"role\": \"system\", \"content\" : \"You are ChatGPT, a large language model trained by OpenAI. Follow the user's instructions carefully. Respond using markdown.\\nKnowledge cutoff: 2021-09-01\\nCurrent date: 2023-03-02\"},\n",
    "                {\"role\": \"user\", \"content\" : prompt},\n",
    "        ],\n",
    "        temperature = 1,\n",
    "        top_p = 1   \n",
    "        )\n",
    "        store_the_persona_question(completion, grade=grade, major=major , prompt=prompt , temperature = 1 , top_p = 1)\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Time of Expected of Graduation Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for time_of_gradiation in range(2023 , 2027):\n",
    "    for grade_number , grade in enumerate([\"undergraduate freshman\", \" undergraduate sophomore\", \"undergraduate junior\", \"undergraduate senior\" , \"master\", \"PHD\"]):\n",
    "        if \"undergraduate\" in grade and grade_number > time_of_gradiation - 2023:\n",
    "            for major in MAJORS:\n",
    "                prompt = f\"Provide a list of questions that a {grade} student who is {major} at University of Texas at Dallas  would create in number format\"\n",
    "                completion = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo\", \n",
    "                messages = [\n",
    "                        {\"role\": \"system\", \"content\" : \"You are ChatGPT, a large language model trained by OpenAI. Follow the user's instructions carefully. Respond using markdown.\\nKnowledge cutoff: 2021-09-01\\nCurrent date: 2023-03-02\"},\n",
    "                        {\"role\": \"user\", \"content\" : prompt},\n",
    "                ],\n",
    "                temperature = 1,\n",
    "                top_p = 1   \n",
    "                )\n",
    "                store_the_persona_question(completion, grade=grade, major=major , prompt=prompt , temperature = 1 , top_p = 1)\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add student Interestes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INTEREST  = [\n",
    "    \"doing research\",\n",
    "    \"graduate school\",\n",
    "    \"doing well in class\",\n",
    "    \"graduate soon as possible\"\n",
    "]\n",
    "## add a suffix in INTEREST\n",
    "INTEREST = [\"interested in \"+ interest for interest in INTEREST]\n",
    "print(INTEREST)\n",
    "## add an empty line \n",
    "INTEREST.append(\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for interest in INTEREST:\n",
    "    for grade_number , grade in enumerate([\"undergraduate freshman\", \" undergraduate sophomore\", \"undergraduate junior\", \"undergraduate senior\" , \"master\", \"PHD\"]):\n",
    "            for major in MAJORS:\n",
    "                \n",
    "                prompt = f\"Provide a list of questions that a {grade} {major} student at UTD {interest} would in number format.\"\n",
    "                completion = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo\", \n",
    "                messages = [\n",
    "                        {\"role\": \"system\", \"content\" : \"You are ChatGPT, a large language model trained by OpenAI. Follow the user's instructions carefully. Respond using markdown.\\nKnowledge cutoff: 2021-09-01\\nCurrent date: 2023-03-02\"},\n",
    "                        {\"role\": \"user\", \"content\" : prompt},\n",
    "                ],\n",
    "                temperature = 1,\n",
    "                top_p = 1   \n",
    "                )\n",
    "                store_the_persona_question(completion, grade=grade, major=major , prompt=prompt , temperature = 1 , top_p = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter the evaluation  of the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'question'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3629\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3628\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3629\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3630\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'question'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/null/code/TemocTalk/backend/persona.ipynb Cell 23\u001b[0m in \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/null/code/TemocTalk/backend/persona.ipynb#X36sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m## if the count is 0 then it is not relevant\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/null/code/TemocTalk/backend/persona.ipynb#X36sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     df\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39mevaluation.csv\u001b[39m\u001b[39m'\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/null/code/TemocTalk/backend/persona.ipynb#X36sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m check_if_it_relevant_question()\n",
      "\u001b[1;32m/home/null/code/TemocTalk/backend/persona.ipynb Cell 23\u001b[0m in \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/null/code/TemocTalk/backend/persona.ipynb#X36sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m list_of_questions_topics \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39minterested in\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/null/code/TemocTalk/backend/persona.ipynb#X36sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m## count the number of time list of questions topics appear in the question\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/null/code/TemocTalk/backend/persona.ipynb#X36sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mcount\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39mquestion\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39msum\u001b[39m([\u001b[39m1\u001b[39m \u001b[39mfor\u001b[39;00m topic \u001b[39min\u001b[39;00m list_of_questions_topics \u001b[39mif\u001b[39;00m topic \u001b[39min\u001b[39;00m x]))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/null/code/TemocTalk/backend/persona.ipynb#X36sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m## if the count is 0 then it is not relevant\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/null/code/TemocTalk/backend/persona.ipynb#X36sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m df\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39mevaluation.csv\u001b[39m\u001b[39m'\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3506\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3631\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3629\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3630\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3631\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3632\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3633\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3634\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3635\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3636\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'question'"
     ]
    }
   ],
   "source": [
    "def check_if_it_relevant_question():\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv('evaluation.csv')\n",
    "    list_of_questions_topics = [\"UTD\", \"housing\", \"university\", \"Texas\", \"Dallas\" , \"transfer\" , \"meal plan\" , \"GPA\" , \"study\" , \"abroad\"]\n",
    "    list_of_questions_topics += MAJORS\n",
    "    list_of_questions_topics += INTEREST\n",
    "    list_of_questions_topics += [\"undergraduate\", \"graduate\", \"freshman\", \"sophomore\", \"junior\", \"senior\", \"master\", \"PHD\"]\n",
    "    list_of_questions_topics += [\"interested in\"]\n",
    "    ## count the number of time list of questions topics appear in the question\n",
    "    df['count'] = df['Question'].apply(lambda x: sum([1 for topic in list_of_questions_topics if topic in x]))\n",
    "    ## if the count is 0 then it is not relevant\n",
    "    df.to_csv('evaluation.csv', index=False)\n",
    "check_if_it_relevant_question()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temoctalk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
